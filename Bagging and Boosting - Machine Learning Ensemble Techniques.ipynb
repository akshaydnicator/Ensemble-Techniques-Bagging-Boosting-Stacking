{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required modules\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, BaggingClassifier, RandomForestClassifier, VotingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn import metrics\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc1</th>\n",
       "      <th>pc2</th>\n",
       "      <th>pc3</th>\n",
       "      <th>pc4</th>\n",
       "      <th>pc5</th>\n",
       "      <th>pc6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.532196</td>\n",
       "      <td>-0.372043</td>\n",
       "      <td>0.305666</td>\n",
       "      <td>-0.546590</td>\n",
       "      <td>0.135447</td>\n",
       "      <td>0.009730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.389258</td>\n",
       "      <td>-0.045656</td>\n",
       "      <td>-0.573600</td>\n",
       "      <td>-0.017898</td>\n",
       "      <td>-0.057655</td>\n",
       "      <td>-0.232852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.293952</td>\n",
       "      <td>-0.467042</td>\n",
       "      <td>0.134255</td>\n",
       "      <td>-0.177374</td>\n",
       "      <td>-0.261998</td>\n",
       "      <td>0.795718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.378499</td>\n",
       "      <td>0.394433</td>\n",
       "      <td>0.677732</td>\n",
       "      <td>-0.340884</td>\n",
       "      <td>-0.220230</td>\n",
       "      <td>-0.150057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.532253</td>\n",
       "      <td>-0.371999</td>\n",
       "      <td>0.305718</td>\n",
       "      <td>-0.546631</td>\n",
       "      <td>0.135432</td>\n",
       "      <td>0.009699</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pc1       pc2       pc3       pc4       pc5       pc6\n",
       "0  0.532196 -0.372043  0.305666 -0.546590  0.135447  0.009730\n",
       "1 -0.389258 -0.045656 -0.573600 -0.017898 -0.057655 -0.232852\n",
       "2 -0.293952 -0.467042  0.134255 -0.177374 -0.261998  0.795718\n",
       "3 -0.378499  0.394433  0.677732 -0.340884 -0.220230 -0.150057\n",
       "4  0.532253 -0.371999  0.305718 -0.546631  0.135432  0.009699"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import original train set and Principal Components (PCs) obtained from PCA done in other notebook\n",
    "df = pd.read_csv('train.csv')\n",
    "pca_train = pd.read_csv('pca_train.csv')\n",
    "pca_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the Categorical Y/N target variable 'Loan_Status' for binary 1/0 classification\n",
    "df['Loan_Status'] = df['Loan_Status'].map(lambda x: 1 if x == 'Y' else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set X and y for ML model training do train-test split using sklearn module\n",
    "\n",
    "X = pca_train.values\n",
    "y = df['Loan_Status']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(93,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(521, 6)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 out of  90 | elapsed:    3.6s remaining:    6.0s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None,\n",
       "          learning_rate=1.0, n_estimators=50, random_state=None),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': array([1, 2, 3, 4, 5, 6, 7, 8, 9])},\n",
       "       pre_dispatch='128*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate a new Adaptive Classifier, an ensemble boosting algorithm\n",
    "ada = AdaBoostClassifier()\n",
    "\n",
    "# Create a dictionary of all values we want to test for selected model parameters of the respective algorithm\n",
    "params_ada = {'n_estimators': np.arange(1, 10)}\n",
    "\n",
    "# Use GridSearchCV to test all values for selected model parameters\n",
    "ada_gs = GridSearchCV(ada, params_ada, cv=10, verbose=1, n_jobs=-1, pre_dispatch='128*n_jobs')\n",
    "\n",
    "# Fit model to training data\n",
    "ada_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 1}\n"
     ]
    }
   ],
   "source": [
    "# Save the best model\n",
    "ada_best = ada_gs.best_estimator_\n",
    "\n",
    "# Check the value of the best selected model parameter(s)\n",
    "print(ada_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ada: 0.8064516129032258\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy score on the test data using best model\n",
    "print('ada: {}'.format(ada_best.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 199 candidates, totalling 1990 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 288 tasks      | elapsed:    4.0s\n",
      "[Parallel(n_jobs=-1)]: Done 738 tasks      | elapsed:   19.2s\n",
      "[Parallel(n_jobs=-1)]: Done 1288 tasks      | elapsed:   56.1s\n",
      "[Parallel(n_jobs=-1)]: Done 1990 out of 1990 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=GradientBoostingClassifier(criterion='friedman_mse', init=None,\n",
       "              learning_rate=0.005, loss='deviance', max_depth=3,\n",
       "              max_features=None, max_leaf_nodes=None,\n",
       "              min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "              min_samples_leaf=1, min_sam...       subsample=1.0, tol=0.0001, validation_fraction=0.1,\n",
       "              verbose=0, warm_start=True),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': array([  1,   2, ..., 198, 199])},\n",
       "       pre_dispatch='128*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate a new Gradient Boosting Classifier, an ensemble boosting algorithm\n",
    "gbc = GradientBoostingClassifier(learning_rate=0.005,warm_start=True)\n",
    "\n",
    "# Create a dictionary of all values we want to test for selected model parameters of the respective algorithm\n",
    "params_gbc = {'n_estimators': np.arange(1, 200)}\n",
    "\n",
    "# Use GridSearchCV to test all values for selected model parameters\n",
    "gbc_gs = GridSearchCV(gbc, params_gbc, cv=10, verbose=1, n_jobs=-1, pre_dispatch='128*n_jobs')\n",
    "\n",
    "# Fit model to training data\n",
    "gbc_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 176}\n"
     ]
    }
   ],
   "source": [
    "# Save the best model\n",
    "gbc_best = gbc_gs.best_estimator_\n",
    "\n",
    "# Check the value of the best selected model parameter(s)\n",
    "print(gbc_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbc: 0.8064516129032258\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy score on the test data using best model\n",
    "print('gbc: {}'.format(gbc_best.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 99 candidates, totalling 990 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 288 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done 990 out of 990 | elapsed:  2.2min finished\n",
      "C:\\Users\\Akshay Kaushal\\.conda\\envs\\nlp_course\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=BaggingClassifier(base_estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            ...stimators=10, n_jobs=None, oob_score=False,\n",
       "         random_state=None, verbose=0, warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': array([ 1,  2, ..., 98, 99])},\n",
       "       pre_dispatch='128*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate a new Bagging Classifier, an ensemble bagging algorithm \n",
    "bcdt = BaggingClassifier(DecisionTreeClassifier(random_state=1))\n",
    "\n",
    "# Create a dictionary of all values we want to test for selected model parameters of the respective algorithm\n",
    "params_bcdt = {'n_estimators': np.arange(1, 100)}\n",
    "\n",
    "# Use GridSearchCV to test all values for selected model parameters\n",
    "bcdt_gs = GridSearchCV(bcdt, params_bcdt, cv=10, verbose=1, n_jobs=-1, pre_dispatch='128*n_jobs')\n",
    "\n",
    "# Fit model to training data\n",
    "bcdt_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 15}\n"
     ]
    }
   ],
   "source": [
    "# Save the best model\n",
    "bcdt_best = bcdt_gs.best_estimator_\n",
    "\n",
    "# Check the value of the best selected model parameter(s)\n",
    "print(bcdt_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "bcdt: 0.7741935483870968\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy score on the test data using best model\n",
    "print('bcdt: {}'.format(bcdt_best.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=None,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=1,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=-1, param_grid={},\n",
       "       pre_dispatch='128*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate a new Decision Tree Classifier and follow the similar process as mentioned in comments above\n",
    "dt = DecisionTreeClassifier(random_state=1)\n",
    "params_dt = {}\n",
    "dt_gs = GridSearchCV(dt, params_dt, cv=10, verbose=1, n_jobs=-1, pre_dispatch='128*n_jobs')\n",
    "dt_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Save the best model and check best model parameters\n",
    "dt_best = dt_gs.best_estimator_\n",
    "print(dt_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dt: 0.7311827956989247\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy score on the test data using best model\n",
    "print('dt: {}'.format(dt_best.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 1 candidates, totalling 10 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   5 out of  10 | elapsed:    0.1s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.1s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=LinearSVC(C=1.0, class_weight=None, dual=True, fit_intercept=True,\n",
       "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
       "     multi_class='ovr', penalty='l2', random_state=1, tol=0.0001,\n",
       "     verbose=0),\n",
       "       fit_params=None, iid='warn', n_jobs=-1, param_grid={},\n",
       "       pre_dispatch='128*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate a new Support Vector Classifier and follow the similar process as mentioned in comments above\n",
    "svc = LinearSVC(random_state=1)\n",
    "params_svc = {}\n",
    "svc_gs = GridSearchCV(svc, params_svc, cv=10,verbose=1,n_jobs=-1,pre_dispatch='128*n_jobs')\n",
    "svc_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n"
     ]
    }
   ],
   "source": [
    "# Save the best model and check best model parameters\n",
    "svc_best = svc_gs.best_estimator_\n",
    "print(svc_gs.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "svc: 0.7956989247311828\n"
     ]
    }
   ],
   "source": [
    "# Print the accuracy score on the test data using best model\n",
    "print('svc: {}'.format(svc_best.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 297 candidates, totalling 2970 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 288 tasks      | elapsed:    3.0s\n",
      "[Parallel(n_jobs=-1)]: Done 738 tasks      | elapsed:   11.7s\n",
      "[Parallel(n_jobs=-1)]: Done 1288 tasks      | elapsed:   22.0s\n",
      "[Parallel(n_jobs=-1)]: Done 1938 tasks      | elapsed:   39.9s\n",
      "[Parallel(n_jobs=-1)]: Done 2970 out of 2970 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
       "       learning_rate=0.005, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "       nthread=None, objective='binary:logistic', random_state=1,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=None, subsample=1, verbosity=1),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'max_depth': array([2, 3, 4]), 'n_estimators': array([ 1,  2, ..., 98, 99])},\n",
       "       pre_dispatch='128*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate a new XG Boost Classifier, an ensemble boosting algorithm and follow the similar process as mentioned in comments above\n",
    "xg = xgb.XGBClassifier(random_state=1,learning_rate=0.005)\n",
    "params_xg = {'max_depth': np.arange(2,5), 'n_estimators': np.arange(1, 100)}\n",
    "xg_gs = GridSearchCV(xg, params_xg, cv=10, verbose=1, n_jobs=-1, pre_dispatch='128*n_jobs')\n",
    "xg_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'max_depth': 2, 'n_estimators': 2}\n",
      "xg: 0.8064516129032258\n"
     ]
    }
   ],
   "source": [
    "# Save the best model and check best model parameters\n",
    "xg_best = xg_gs.best_estimator_\n",
    "print(xg_gs.best_params_)\n",
    "\n",
    "# Print the accuracy score on the test data using best model\n",
    "print('xg: {}'.format(xg_best.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiate a new Light Gradient Boosted Machine, an ensemble boosting algorithm\n",
    "\n",
    "# Set the train data and initiate ML training\n",
    "train_data = lgb.Dataset(X_train,label=y_train)\n",
    "params = {'learning_rate':0.01}\n",
    "lgbm = lgb.train(params, train_data, 100) \n",
    "\n",
    "y_pred = lgbm.predict(X_test)\n",
    "\n",
    "for i in range(0,y_test.shape[0]):\n",
    "    if y_pred[i]>=0.5:\n",
    "        y_pred[i]=1\n",
    "    else:\n",
    "        y_pred[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8064516129032258\n"
     ]
    }
   ],
   "source": [
    "# Print the overall accuracy\n",
    "print(metrics.accuracy_score(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Learning rate set to 0.06442\n",
      "0:\tlearn: 0.6730757\ttotal: 57.5ms\tremaining: 5.69s\n",
      "1:\tlearn: 0.6557088\ttotal: 61.4ms\tremaining: 3.01s\n",
      "2:\tlearn: 0.6397677\ttotal: 65.3ms\tremaining: 2.11s\n",
      "3:\tlearn: 0.6248063\ttotal: 69.1ms\tremaining: 1.66s\n",
      "4:\tlearn: 0.6109242\ttotal: 73ms\tremaining: 1.39s\n",
      "5:\tlearn: 0.5993601\ttotal: 76.9ms\tremaining: 1.21s\n",
      "6:\tlearn: 0.5879616\ttotal: 80.8ms\tremaining: 1.07s\n",
      "7:\tlearn: 0.5767795\ttotal: 84.6ms\tremaining: 973ms\n",
      "8:\tlearn: 0.5673600\ttotal: 88.4ms\tremaining: 894ms\n",
      "9:\tlearn: 0.5582118\ttotal: 92.3ms\tremaining: 831ms\n",
      "10:\tlearn: 0.5509164\ttotal: 96ms\tremaining: 777ms\n",
      "11:\tlearn: 0.5433785\ttotal: 99.6ms\tremaining: 731ms\n",
      "12:\tlearn: 0.5365546\ttotal: 103ms\tremaining: 692ms\n",
      "13:\tlearn: 0.5301993\ttotal: 107ms\tremaining: 658ms\n",
      "14:\tlearn: 0.5234929\ttotal: 111ms\tremaining: 629ms\n",
      "15:\tlearn: 0.5179924\ttotal: 115ms\tremaining: 602ms\n",
      "16:\tlearn: 0.5125370\ttotal: 118ms\tremaining: 578ms\n",
      "17:\tlearn: 0.5078143\ttotal: 122ms\tremaining: 557ms\n",
      "18:\tlearn: 0.5035376\ttotal: 126ms\tremaining: 537ms\n",
      "19:\tlearn: 0.4988116\ttotal: 130ms\tremaining: 519ms\n",
      "20:\tlearn: 0.4950427\ttotal: 134ms\tremaining: 505ms\n",
      "21:\tlearn: 0.4916040\ttotal: 138ms\tremaining: 490ms\n",
      "22:\tlearn: 0.4883079\ttotal: 142ms\tremaining: 475ms\n",
      "23:\tlearn: 0.4847853\ttotal: 146ms\tremaining: 461ms\n",
      "24:\tlearn: 0.4809036\ttotal: 149ms\tremaining: 448ms\n",
      "25:\tlearn: 0.4781385\ttotal: 153ms\tremaining: 435ms\n",
      "26:\tlearn: 0.4755684\ttotal: 157ms\tremaining: 423ms\n",
      "27:\tlearn: 0.4727789\ttotal: 161ms\tremaining: 413ms\n",
      "28:\tlearn: 0.4697539\ttotal: 165ms\tremaining: 403ms\n",
      "29:\tlearn: 0.4671146\ttotal: 169ms\tremaining: 393ms\n",
      "30:\tlearn: 0.4652867\ttotal: 172ms\tremaining: 384ms\n",
      "31:\tlearn: 0.4634438\ttotal: 176ms\tremaining: 374ms\n",
      "32:\tlearn: 0.4618740\ttotal: 180ms\tremaining: 365ms\n",
      "33:\tlearn: 0.4599415\ttotal: 183ms\tremaining: 356ms\n",
      "34:\tlearn: 0.4580530\ttotal: 187ms\tremaining: 347ms\n",
      "35:\tlearn: 0.4563005\ttotal: 190ms\tremaining: 338ms\n",
      "36:\tlearn: 0.4549877\ttotal: 194ms\tremaining: 330ms\n",
      "37:\tlearn: 0.4532695\ttotal: 198ms\tremaining: 323ms\n",
      "38:\tlearn: 0.4517009\ttotal: 201ms\tremaining: 315ms\n",
      "39:\tlearn: 0.4504325\ttotal: 205ms\tremaining: 307ms\n",
      "40:\tlearn: 0.4487633\ttotal: 208ms\tremaining: 300ms\n",
      "41:\tlearn: 0.4474635\ttotal: 212ms\tremaining: 293ms\n",
      "42:\tlearn: 0.4461672\ttotal: 216ms\tremaining: 286ms\n",
      "43:\tlearn: 0.4445100\ttotal: 219ms\tremaining: 279ms\n",
      "44:\tlearn: 0.4436834\ttotal: 223ms\tremaining: 273ms\n",
      "45:\tlearn: 0.4426211\ttotal: 227ms\tremaining: 266ms\n",
      "46:\tlearn: 0.4415297\ttotal: 230ms\tremaining: 260ms\n",
      "47:\tlearn: 0.4400346\ttotal: 234ms\tremaining: 253ms\n",
      "48:\tlearn: 0.4389770\ttotal: 237ms\tremaining: 247ms\n",
      "49:\tlearn: 0.4382394\ttotal: 241ms\tremaining: 241ms\n",
      "50:\tlearn: 0.4368076\ttotal: 245ms\tremaining: 235ms\n",
      "51:\tlearn: 0.4358796\ttotal: 248ms\tremaining: 229ms\n",
      "52:\tlearn: 0.4350246\ttotal: 252ms\tremaining: 223ms\n",
      "53:\tlearn: 0.4339755\ttotal: 255ms\tremaining: 217ms\n",
      "54:\tlearn: 0.4330911\ttotal: 259ms\tremaining: 212ms\n",
      "55:\tlearn: 0.4324006\ttotal: 262ms\tremaining: 206ms\n",
      "56:\tlearn: 0.4314883\ttotal: 266ms\tremaining: 201ms\n",
      "57:\tlearn: 0.4308050\ttotal: 270ms\tremaining: 196ms\n",
      "58:\tlearn: 0.4298615\ttotal: 274ms\tremaining: 191ms\n",
      "59:\tlearn: 0.4291668\ttotal: 278ms\tremaining: 185ms\n",
      "60:\tlearn: 0.4282103\ttotal: 282ms\tremaining: 180ms\n",
      "61:\tlearn: 0.4275142\ttotal: 286ms\tremaining: 175ms\n",
      "62:\tlearn: 0.4268833\ttotal: 290ms\tremaining: 170ms\n",
      "63:\tlearn: 0.4262309\ttotal: 294ms\tremaining: 165ms\n",
      "64:\tlearn: 0.4251077\ttotal: 298ms\tremaining: 160ms\n",
      "65:\tlearn: 0.4242704\ttotal: 302ms\tremaining: 155ms\n",
      "66:\tlearn: 0.4238925\ttotal: 305ms\tremaining: 150ms\n",
      "67:\tlearn: 0.4230932\ttotal: 309ms\tremaining: 146ms\n",
      "68:\tlearn: 0.4222016\ttotal: 313ms\tremaining: 141ms\n",
      "69:\tlearn: 0.4217784\ttotal: 317ms\tremaining: 136ms\n",
      "70:\tlearn: 0.4209833\ttotal: 320ms\tremaining: 131ms\n",
      "71:\tlearn: 0.4201607\ttotal: 325ms\tremaining: 126ms\n",
      "72:\tlearn: 0.4196217\ttotal: 329ms\tremaining: 122ms\n",
      "73:\tlearn: 0.4189834\ttotal: 332ms\tremaining: 117ms\n",
      "74:\tlearn: 0.4180649\ttotal: 336ms\tremaining: 112ms\n",
      "75:\tlearn: 0.4174125\ttotal: 340ms\tremaining: 107ms\n",
      "76:\tlearn: 0.4165338\ttotal: 344ms\tremaining: 103ms\n",
      "77:\tlearn: 0.4161339\ttotal: 348ms\tremaining: 98.2ms\n",
      "78:\tlearn: 0.4157503\ttotal: 352ms\tremaining: 93.5ms\n",
      "79:\tlearn: 0.4150722\ttotal: 356ms\tremaining: 89ms\n",
      "80:\tlearn: 0.4148293\ttotal: 360ms\tremaining: 84.5ms\n",
      "81:\tlearn: 0.4139804\ttotal: 365ms\tremaining: 80.1ms\n",
      "82:\tlearn: 0.4134270\ttotal: 369ms\tremaining: 75.6ms\n",
      "83:\tlearn: 0.4127417\ttotal: 373ms\tremaining: 71.1ms\n",
      "84:\tlearn: 0.4121085\ttotal: 377ms\tremaining: 66.5ms\n",
      "85:\tlearn: 0.4114559\ttotal: 381ms\tremaining: 62ms\n",
      "86:\tlearn: 0.4107664\ttotal: 385ms\tremaining: 57.5ms\n",
      "87:\tlearn: 0.4103529\ttotal: 388ms\tremaining: 53ms\n",
      "88:\tlearn: 0.4098923\ttotal: 392ms\tremaining: 48.5ms\n",
      "89:\tlearn: 0.4091367\ttotal: 398ms\tremaining: 44.2ms\n",
      "90:\tlearn: 0.4083762\ttotal: 402ms\tremaining: 39.8ms\n",
      "91:\tlearn: 0.4078581\ttotal: 406ms\tremaining: 35.3ms\n",
      "92:\tlearn: 0.4073294\ttotal: 410ms\tremaining: 30.8ms\n",
      "93:\tlearn: 0.4065949\ttotal: 414ms\tremaining: 26.4ms\n",
      "94:\tlearn: 0.4060081\ttotal: 417ms\tremaining: 22ms\n",
      "95:\tlearn: 0.4055657\ttotal: 421ms\tremaining: 17.5ms\n",
      "96:\tlearn: 0.4051619\ttotal: 425ms\tremaining: 13.1ms\n",
      "97:\tlearn: 0.4049740\ttotal: 428ms\tremaining: 8.74ms\n",
      "98:\tlearn: 0.4043446\ttotal: 432ms\tremaining: 4.36ms\n",
      "99:\tlearn: 0.4035927\ttotal: 436ms\tremaining: 0us\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x297002966c8>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate a new Cat Boost Classifier, an ensemble boosting algorithm and fit on train data\n",
    "cbc = CatBoostClassifier(random_state=1, iterations=100)\n",
    "cbc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cbc: 0.8064516129032258\n"
     ]
    }
   ],
   "source": [
    "# Print the overall accuracy\n",
    "print('cbc: {}'.format(cbc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 24 candidates, totalling 240 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done 211 out of 240 | elapsed:    1.4s remaining:    0.1s\n",
      "[Parallel(n_jobs=-1)]: Done 240 out of 240 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
       "           metric_params=None, n_jobs=None, n_neighbors=5, p=2,\n",
       "           weights='uniform'),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_neighbors': array([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "       18, 19, 20, 21, 22, 23, 24])},\n",
       "       pre_dispatch='128*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate a new KNeighbors Classifier and follow the similar process as mentioned in previous comments\n",
    "knn = KNeighborsClassifier()\n",
    "params_knn = {'n_neighbors': np.arange(1, 25)}\n",
    "knn_gs = GridSearchCV(knn, params_knn, cv=10, verbose=1, n_jobs=-1, pre_dispatch='128*n_jobs')\n",
    "knn_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_neighbors': 15}\n",
      "knn: 0.7956989247311828\n"
     ]
    }
   ],
   "source": [
    "# Save the best model and check best model parameters\n",
    "knn_best = knn_gs.best_estimator_\n",
    "print(knn_gs.best_params_)\n",
    "\n",
    "# Print the overall accuracy\n",
    "print('knn: {}'.format(knn_best.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 10 folds for each of 9 candidates, totalling 90 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  34 out of  90 | elapsed:   10.0s remaining:   16.6s\n",
      "[Parallel(n_jobs=-1)]: Done  90 out of  90 | elapsed:   45.7s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=10, error_score='raise-deprecating',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators='warn', n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'n_estimators': [100, 150, 200, 250, 300, 350, 400, 450, 500]},\n",
       "       pre_dispatch='128*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initiate a new Random Forest Classifier, an ensemble bagging algorithm and follow the similar process as mentioned in previous comments\n",
    "rf = RandomForestClassifier()\n",
    "params_rf = {'n_estimators': [100, 150, 200, 250, 300, 350, 400, 450, 500]}\n",
    "rf_gs = GridSearchCV(rf, params_rf, cv=10, verbose=1, n_jobs=-1, pre_dispatch='128*n_jobs')\n",
    "rf_gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'n_estimators': 100}\n",
      "rf: 0.7526881720430108\n"
     ]
    }
   ],
   "source": [
    "# Save the best model and check best model parameters\n",
    "rf_best = rf_gs.best_estimator_\n",
    "print(rf_gs.best_params_)\n",
    "\n",
    "# Print the overall accuracy\n",
    "print('rf: {}'.format(rf_best.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a new Logistic Regression model and fit on train data\n",
    "log_reg = LogisticRegression(solver='lbfgs')\n",
    "log_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log_reg: 0.7956989247311828\n"
     ]
    }
   ],
   "source": [
    "# Print the overall accuracy\n",
    "print('log_reg: {}'.format(log_reg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy of best selected models on X_test dataset\n",
      "\n",
      "knn: 0.7956989247311828\n",
      "rf: 0.7526881720430108\n",
      "log_reg: 0.7956989247311828\n",
      "ada: 0.8064516129032258\n",
      "gbc: 0.8064516129032258\n",
      "bcdt: 0.7741935483870968\n",
      "dt: 0.7311827956989247\n",
      "svc: 0.7956989247311828\n",
      "xg: 0.8064516129032258\n",
      "lgbm: 0.8064516129032258\n",
      "cbc: 0.8064516129032258\n"
     ]
    }
   ],
   "source": [
    "# Print the overall accuracy score for all the 11 best classification models trained earlier\n",
    "print('Overall Accuracy of best selected models on X_test dataset\\n')\n",
    "print('knn: {}'.format(knn_best.score(X_test, y_test)))\n",
    "print('rf: {}'.format(rf_best.score(X_test, y_test)))\n",
    "print('log_reg: {}'.format(log_reg.score(X_test, y_test)))\n",
    "print('ada: {}'.format(ada_best.score(X_test, y_test)))\n",
    "print('gbc: {}'.format(gbc_best.score(X_test, y_test)))\n",
    "print('bcdt: {}'.format(bcdt_best.score(X_test, y_test)))\n",
    "print('dt: {}'.format(dt_best.score(X_test, y_test)))\n",
    "print('svc: {}'.format(svc_best.score(X_test, y_test)))\n",
    "print('xg: {}'.format(xg_best.score(X_test, y_test)))\n",
    "print('lgbm: {}'.format(metrics.accuracy_score(y_test,y_pred)))\n",
    "print('cbc: {}'.format(cbc.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary of our models\n",
    "estimators=[('knn', knn_best), ('rf', rf_best), ('log_reg', log_reg), ('ada', ada_best), ('gbc', gbc_best), ('bcdt', bcdt_best), ('dt', dt_best), ('xg', xg_best), ('cbc', cbc)]\n",
    "\n",
    "# Create a voting classifier, input the dictionary of our models as estimators for the ensemble\n",
    "ensemble = VotingClassifier(estimators, voting='soft', n_jobs=-1, flatten_transform=True, weights=[1/9,1/9,1/9,1/9,1/9,1/9,1/9,1/9,1/9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7956989247311828"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the Final Ensemble Model on train data\n",
    "ensemble.fit(X_train, y_train)\n",
    "\n",
    "# Test our final model on the test data and print our final accuracy score for the Ensemble made using Bagging and Boosting techniques\n",
    "ensemble.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pc1</th>\n",
       "      <th>pc2</th>\n",
       "      <th>pc3</th>\n",
       "      <th>pc4</th>\n",
       "      <th>pc5</th>\n",
       "      <th>pc6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.279674</td>\n",
       "      <td>-0.482089</td>\n",
       "      <td>0.281351</td>\n",
       "      <td>-0.216091</td>\n",
       "      <td>-0.031365</td>\n",
       "      <td>-0.142948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.387792</td>\n",
       "      <td>-0.465299</td>\n",
       "      <td>0.315794</td>\n",
       "      <td>-0.105767</td>\n",
       "      <td>-0.045882</td>\n",
       "      <td>-0.094015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.499361</td>\n",
       "      <td>-0.453305</td>\n",
       "      <td>0.346596</td>\n",
       "      <td>0.008040</td>\n",
       "      <td>-0.060596</td>\n",
       "      <td>-0.039688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.492062</td>\n",
       "      <td>-0.414947</td>\n",
       "      <td>0.365367</td>\n",
       "      <td>0.070814</td>\n",
       "      <td>0.079475</td>\n",
       "      <td>-0.018593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.437441</td>\n",
       "      <td>0.509004</td>\n",
       "      <td>0.706130</td>\n",
       "      <td>-0.674169</td>\n",
       "      <td>-0.054470</td>\n",
       "      <td>-0.001153</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        pc1       pc2       pc3       pc4       pc5       pc6\n",
       "0 -0.279674 -0.482089  0.281351 -0.216091 -0.031365 -0.142948\n",
       "1 -0.387792 -0.465299  0.315794 -0.105767 -0.045882 -0.094015\n",
       "2 -0.499361 -0.453305  0.346596  0.008040 -0.060596 -0.039688\n",
       "3 -0.492062 -0.414947  0.365367  0.070814  0.079475 -0.018593\n",
       "4  0.437441  0.509004  0.706130 -0.674169 -0.054470 -0.001153"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the PCs of test data for final predictions\n",
    "dft = pd.read_csv('pca_test.csv')\n",
    "dft.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "367\n"
     ]
    }
   ],
   "source": [
    "# Assign the PCs dft to test_X\n",
    "test_X = dft.values\n",
    "print(len(test_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1,\n",
       "       0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1,\n",
       "       0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0,\n",
       "       1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make final predictions on the test data\n",
    "test_predictions = ensemble.predict(test_X)\n",
    "test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import original test file for Loan_IDs and assign the test_predictions to a new column 'Loan_Status'\n",
    "dft2 = pd.read_csv('test.csv')\n",
    "dft2['Loan_Status'] = test_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001015</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001022</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001035</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001051</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID  Loan_Status\n",
       "0  LP001015            1\n",
       "1  LP001022            1\n",
       "2  LP001031            1\n",
       "3  LP001035            1\n",
       "4  LP001051            0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop unnecessary columns\n",
    "dft2 = dft2.drop(['Gender','Married','Dependents','Education','Self_Employed','ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term','Credit_History','Property_Area'],axis=1)\n",
    "dft2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loan_ID</th>\n",
       "      <th>Loan_Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LP001015</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LP001022</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LP001031</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LP001035</td>\n",
       "      <td>Y</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LP001051</td>\n",
       "      <td>N</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Loan_ID Loan_Status\n",
       "0  LP001015           Y\n",
       "1  LP001022           Y\n",
       "2  LP001031           Y\n",
       "3  LP001035           Y\n",
       "4  LP001051           N"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convert binary 1/0 targets back to Categorical Y/N alphabets\n",
    "dft2['Loan_Status'] = dft2['Loan_Status'].map(lambda x: 'Y' if x == 1 else 'N')\n",
    "dft2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the predictions from the final Ensemble on local disk\n",
    "dft2.to_csv('Ensemble.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.7 64-bit ('nlp_course': conda)",
   "language": "python",
   "name": "python37764bitnlpcourseconda9a49d315d5b740b588874cc804e7d723"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
